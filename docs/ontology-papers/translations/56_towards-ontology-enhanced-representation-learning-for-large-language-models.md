# [56] 온톨로지 강화 표현학습을 향하여

- 영문 제목: Towards Ontology-Enhanced Representation Learning for Large Language Models
- 연도: 2024
- 원문 링크: https://doi.org/10.48550/arXiv.2405.20527
- DOI: 10.48550/arxiv.2405.20527
- 원문 저장 상태: pdf_saved
- 원문 파일: /Volumes/SAMSUNG/apps/projects/vive-md/docs/ontology-papers/originals/56_towards-ontology-enhanced-representation-learning-for-large-language-models.pdf
- 번역 상태: partial_translated

## 원문(추출 텍스트)

Towards Ontology-Enhanced Representation Learning for Large Language Models
Towards Ontology-Enhanced Representation Learning for
Large Language Models
Francesco Ronzano francesco.ronzano@iqvia.com
IQVIA
Jay Nanavati jay.nanavati@iqvia.com
IQVIA
Abstract
Taking advantage of the widespread use of ontologies to organise and harmonize knowl-
edge across several distinct domains, this paper proposes a novel approach to improve an
embedding-Large Language Model (embedding-LLM) of interest by infusing the knowledge
formalized by a reference ontology: ontological knowledge infusion aims at boosting the
ability of the considered LLM to effectively model the knowledge domain described by the
infused ontology. The linguistic information (i.e. concept synonyms and descriptions) and
structural information (i.e. is-a relations) formalized by the ontology are utilized to com-
pile a comprehensive set of concept definitions, with the assistance of a powerful generative
LLM (i.e. GPT-3.5-turbo). These concept definitions are then employed to fine-tune the
target embedding-LLM using a contrastive learning framework. To demonstrate and evalu-
ate the proposed approach, we utilize the biomedical disease ontology MONDO. The results
show that embedding-LLMs enhanced by ontological disease knowledge exhibit an improved
capability to effectively evaluate the similarity of in-domain sentences from biomedical doc-
uments mentioning diseases, without compromising their out-of-domain performance.
Keywords: knowledge infusion, biomedical ontology, large language model, contrastive
learning, representation learning, sentence similarity
1 Introduction
The availability of high-quality textual data is essential to boost the ability of LLMs to
effectively understand, model and reason about the semantics of a text. With this respect,
recently, Synthetic Textual Data Augmentation methods have been gaining an increasing
relevance: very large, pre-trained LLMs have been often exploited to generate, restructure or
annotate textual data that in turns is exploited to enhance smaller, domain specific LLMs
(Ding et al., 2024; Tan et al., 2024). Besides synthetic data, the structured information
included in a diverse set of knowledge resources has also been used to boost LLMs giving
rise to several proposals of Knowledge-resource Driven LLM-enhancement techniques (Hu
et al., 2023): for example, knowledge graphs represent the most relevant type of knowledge
resources exploited to this purpose (Yang et al., 2024; Yasunaga et al., 2022).
1
arXiv:2405.20527v1  [cs.CL]  30 May 2024

Francesco Ronzano and Jay Nanavati
Knowledge resources like ontologies are extensively used to organise and harmonize in-
formation inside and across a wide range of distinct domains and applications (Patel and
Debnath, 2024). Various methods have been proposed to improve machine learning model
performance by relying on ontologies and vice-versa (Kulmanov et al., 2020): recent exam-
ples include ontology-driven interaction with and fine-tuning of generative LLMs (Palagin
et al., 2023; Baldazzi et al., 2023), ontology-based refinement of knowledge graph queries
(Allemang and Sequeda, 2024) and exploitation of LLMs to create or enrich ontologies
(Ciatto et al., 2024; Mateiu and Groza, 2023).
In this stream of works, the main contribution proposed and evaluated by this paper
is a novel, automated approach to infuse external knowledge, formalized by
an ontology of interest, into an embedding-LLM (i.e. text encoder) 1. This is
achieved by leveraging on both: (i) the linguistic and structural information formalized by
an ontology (Knowledge-resource Driven LLM-enhancement) and (ii) a powerful generative
LLM (i.e. GPT-3.5-turbo) to perform Synthetic Textual Data Augmentation . By using
the generative LLM, a rich set of real and/or synthetic definitions are gathered for all
the concepts specified by the considered ontology. These definitions are then exploited to
create training samples useful to fine-tune a the target embedding-LLM by a contrastive
learning framework: training samples (i.e. pairs of similar and dissimilar definitions) are
generated by following a principled approach, aimed at maximizing their effectiveness for
fine-tuning. Once fine-tuning finalizes, the vectorial representations of texts generated by
the embedding-LLM will incorporate the knowledge formalized by the considered ontology.
2 Related work
Recently, several contrastive representation learning approaches have been proposed to im-
prove the quality of text embeddings by exploiting collections of pairs of related or similar
texts (e.g. query-answer, texts conveying the same meaning, etc.) to fine tune embedding-
LLMs: the quality of embeddings is improved by increasing the similarity of the LLM-
generated vectorial representations of semantically close texts (Hadsell et al., 2006). Ex-
amples of contrastive learning frameworks include Sentence-BERT (Reimers and Gurevych,
2019) where a dual-encoder network architecture, coupled with multiple loss functions is
used to fine-tune text embeddings in a supervised way. SimCSE (Gao et al., 2021) proposes
to use distinct LLM dropout masks as data augmentation strategies to generate pairs of
similar emeddings for unsupervised fine-tuning of embedding-LLMs in a contrastive objec-
tive. Schick and Sch¨ utze (2021) use generative LLMs to create labelled text pairs useful
for unsupervised fine-tuning of embedding-LLMs. Also Wang et al. (2023) relies on gener-
ative LLMs (i.e. GPT-3.5-turbo and GPT-4) to generate synthetic training data spanning
over multiple tasks and languages: this data is then exploited to fine-tune Mistral-7b, a
decoder-only LLM to generate better emeddings. Su et al. (2022) extend the text excerpt
to be embedded with free-text instructions describing the task the embedding will be used
for. Overall, a common paradigm exploited to fine-tune embedding-LLMs by contrastive
learning relies on a contrastive pre-training phase that exploits collections of text pairs
generated semi-automatically by weak supervision, followed by a fine-tuning phase where
LLMs are improved by relying on higher-quality annotated datasets (Li et al., 2023; Wang
1. Implementation available on GitHub repository: https://github.com/iqvianlp/llm-onto-infuse/.
2

Towards Ontology-Enhanced Representation Learning for Large Language Models
et al., 2022). Besides data augmentation approaches, two additional key ingredients useful
to boost the effectiveness of contrastive learning frameworks exploited to generate better
text embeddings are (i) the strategy to select of text pairs that will constitute training
samples and (ii) the choice of the training objective (i.e. loss function) (Wang and Dou,
2023). In Liu et al. (2020), synonyms of biomedical concepts retrieved from the UMLS meta-
thesaurus (Bodenreider, 2004) are exploited to fine-tune embedding-LLMs by contrastive
learning. In comparison, our ontological knowledge infusion approach aims at enhancing
embedding-LLMs by: (i) taking advantage of a richer set of linguistic and structural fea-
tures of ontologies (beyond synonymy); (ii) exploiting the text of whole sentences (instead
of noun phrases) to fine-tune embedding-LLMs; (iii) proposing a novel, automated approach
to create training text pairs.
3 Workflow to infuse ontological knowledge in embedding-LLMs
The proposed approach to infuse ontological knowledge in embedding-LLMs relies on lin-
guistic features - synonym terms and definitions - and structural features - taxonomic
relations - that characterize the set of concepts defined by an ontology. As better detailed
in the next Sections, these features, shared by most ontologies, are exploited to support
and drive: (i) the generation of text excerpts describing the concepts of the ontology and
(ii) the effective aggregation of these text excerpts into pairs of similar or dissimilar ones ,
to be exploited to fine-tune embedding-LLMs.
3.1 Fine-tuning embedding-LLMs by contrastive learning
The the textual information (i.e. definitions of ontological concepts) gathered by relying on
a reference ontology is infused in an embedding-LLMs of choice by fine-tuning such LLM
in a contrsative objective.
3.1.1 Contrastive learning architecture and training objective
In our experiments we rely on the contrastive learning framework described by Chen et al.
(2020) to perform ontological knowledge infusion. In principle, we can infuse ontological
knowledge in any embedding-LLM ( EM B) capable of generating, given a text t, the cor-
responding dense vectorial representation ht = EM B(t) ∈ Rn, where n represents the
dimension of ht, the text embedding 2. Let suppose to have at our disposal a collection of
I pairs of semantically related texts ( ti, t+
i ), where 0 < i < = I. Considering batches of N
pairs of semantically related texts, the corresponding pairs of embeddings ( hi, h+
i ) can be
computed by relying on the LLM ( EM B). The categorical cross-entropy loss is exploited
to favour, for each embedding hi, the identification of (i.e. prediction of the class associated
to) the associated positive embedding h+
i : samples from other embedding pairs in the same
batch are considered as noise. This training objective, referred to as InfoNCE loss (Oord
2. Depending on the specific scenario and embedding-LLM considered, the embedding ht can be generated
by distinct strategies, including pooling of single-token embeddings or by considering special-purpose
tokens of the embedding-LLM (e.g. the CLS token).
3

Francesco Ronzano and Jay Nanavati
et al., 2018), is described by the following formula:
lossi = −log esim(hi,h+
i )/τ
PN
i=1 esim(hi,h+
j )/τ (1)
where N is the batch size and τ is the temperature. sim(p, q) is the similarity function
between the embeddings p and q: it is common practice to use cosine similarity.
It has been shown that when InfoNCE loss is exploited, the quality of learned embeddings
improves sensibly if in each batch, for each pair of semantically related texts ( ti, t+
i ), one
(or more) hard negative texts are included (Chen et al., 2017; Gao et al., 2021). Given
a pair of positive texts, an associated hard negative sample w is a text that is semantically
distinct from the texts ti and t+
i , even if its embedding hw = EM B(w) is characterized
by a high semantic similarity with the embeddings of any positive text (i.e. hi and h+
i ).
Therefore, if for each positive text pair one or more hard negative texts are selected, each
training sample exploited by the considered contrastive learning framework and training
objective would be represented by the tuple of texts ( ti, t+
i , wHN 1
i , ..., wHN K
i , ) where ti and
t+
i represent the pair of positive texts, while wHN k
i , with 0 < i < = K, are the associated K
hard negative samples 3.
3.1.2 Ontology-driven creation of training samples
This Section describes the novel procedure we devise to create training samples useful
to infuse ontological knowledge into an embedding-LLM of our choice, in a contrastive
objective. After generating synthetic definitions of the concepts included in the considered
ontology by prompting a generative LLM, we exploit these definitions in order to create
training samples, thus selecting positive text pairs as well as associated hard negative texts.
Prompting LLMs to generate synthetic concept definitions : our ontological
knowledge infusion approach is based on the availability of textual contents describing the
concepts formalized by the ontology of choice: in the current setting, we focus on concept
definitions4. Ontologies could include definitions of (part of) their concepts. To guarantee
the availability of at least one definition associated to each concept, generative LLMs are
prompted to create synthetic definitions: for each synonym of an ontology concept, a one-
sentence synthetic definition of that concept is collected (see part (a) of Figure 1). The
structure of the definition-generation prompt i

## 한국어 번역

대규모 언어 모델을 위한 온톨로지 강화 표현 학습을 향하여
온톨로지 강화 표현 학습을 향하여
대규모 언어 모델
프란체스코 론자노 francesco.ronzano@iqvia.com
아이큐비아
제이 나나바티 jay.nanavati@iqvia.com
아이큐비아
초록
지식을 조직하고 조화시키기 위해 온톨로지의 광범위한 사용을 활용합니다.
여러 가지 서로 다른 영역에 걸쳐 우위를 확보하기 위해 이 논문은
지식을 주입하여 관심 있는 임베딩-LLM(embedding-LLM)
참조 온톨로지에 의해 공식화됨: 온톨로지 지식 주입은
고려된 LLM이 설명하는 지식 영역을 효과적으로 모델링하는 능력
주입된 온톨로지. 언어적 정보(예: 개념 동의어 및 설명) 및
온톨로지에 의해 공식화된 구조적 정보(즉, is-a 관계)는 다음과 같은 작업에 활용됩니다.
강력한 생성 도구의 도움을 받아 포괄적인 개념 정의 세트를 쌓습니다.
LLM(예: GPT-3.5 터보). 그런 다음 이러한 개념 정의를 사용하여
대조 학습 프레임워크를 사용하여 Embedding-LLM을 타겟팅합니다. 시연하고 평가하려면
제안된 접근 방식을 적용한 후, 우리는 생물의학 질병 온톨로지 MONDO를 활용합니다. 결과
존재론적 질병 지식에 의해 강화된 임베딩 LLM이 개선된 결과를 나타냄을 보여줍니다.
생물의학 문서에서 도메인 내 문장의 유사성을 효과적으로 평가할 수 있는 능력
도메인 외부 성능을 저하시키지 않으면서 질병을 언급하는 항목입니다.
키워드: 지식 주입, 생물의학 온톨로지, 대규모 언어 모델, 대조
학습, 표현학습, 문장유사성
1 소개
고품질 텍스트 데이터의 가용성은 LLM의 능력을 향상시키는 데 필수적입니다.
텍스트의 의미를 효과적으로 이해하고, 모델링하고, 추론합니다. 이에 대하여,
최근에는 합성 텍스트 데이터 확장(Synthetic Textual Data Augmentation) 방법이 점점 더 많이 사용되고 있습니다.
관련성: 매우 크고 사전 훈련된 LLM은 생성, 재구성 또는
더 작은 도메인별 LLM을 향상시키는 데 활용되는 텍스트 데이터에 주석을 답니다.
(Ding 외, 2024; Tan 외, 2024). 합성 데이터 외에도 구조화된 정보
다양한 지식 자원 세트에 포함된 지식은 LLM 제공을 강화하는 데에도 사용되었습니다.
지식 자원 기반 LLM 강화 기술에 대한 여러 제안이 제기되었습니다(Hu
et al., 2023): 예를 들어 지식 그래프는 가장 관련성이 높은 지식 유형을 나타냅니다.
이러한 목적으로 활용되는 자원입니다(Yang et al., 2024; Yasunaga et al., 2022).
1
arXiv:2405.20527v1 [cs.CL] 2024년 5월 30일

프란체스코 론자노와 제이 나나바티
온톨로지와 같은 지식 자원은 다음을 조직하고 조화시키는 데 광범위하게 사용됩니다.
광범위한 개별 도메인 및 애플리케이션 내부 및 전반에 걸쳐 형성됩니다(Patel 및
데브나스, 2024). 머신러닝 모델을 개선하기 위한 다양한 방법이 제안되었습니다.
온톨로지에 의존하는 성능과 그 반대의 경우(Kulmanov et al., 2020): 최근 시험-
여기에는 생성적 LLM(Palagin)과의 온톨로지 기반 상호 작용 및 미세 조정이 포함됩니다.
외, 2023; Baldazzi et al., 2023), 지식 그래프 쿼리의 온톨로지 기반 개선
(Allemang and Sequeda, 2024) 및 온톨로지를 생성하거나 강화하기 위한 LLM 활용
(Ciatto 외, 2024; Mateiu 및 Groza, 2023).
이러한 연구 흐름에서 본 논문이 제안하고 평가한 주요 공헌은
외부 지식을 주입하기 위한 새롭고 자동화된 접근 방식으로,
관심 있는 온톨로지를 embedding-LLM(예: 텍스트 인코더)로 변환 1. 이는 다음과 같습니다.
(i) 다음에 의해 공식화되는 언어적, 구조적 정보를 모두 활용하여 달성됩니다.
온톨로지(지식 자원 기반 LLM 강화) 및 (ii) 강력한 생성
합성 텍스트 데이터 확대를 수행하는 LLM(예: GPT-3.5-turbo) 사용하여
풍부한 실제 및/또는 합성 정의 세트인 생성적 LLM이 모든 사용자를 위해 수집됩니다.
고려된 온톨로지에 의해 지정된 개념. 그런 다음 이러한 정의를 활용하여
대조를 통해 대상 임베딩 LLM을 미세 조정하는 데 유용한 훈련 샘플을 만듭니다.
학습 프레임워크: 훈련 샘플(즉, 유사한 정의와 다른 정의의 쌍)은
효율성을 극대화하는 것을 목표로 하는 원칙적인 접근 방식을 따라 생성되었습니다.
미세 조정. 미세 조정이 완료되면 생성된 텍스트의 벡터 표현은 다음과 같습니다.
Embedding-LLM은 고려된 온톨로지에 의해 공식화된 지식을 통합합니다.
2 관련 작품
최근에는 여러 가지 대조 표현 학습 접근법이 제안되었습니다.
관련되거나 유사한 쌍의 모음을 활용하여 텍스트 임베딩의 품질을 증명합니다.
임베딩을 미세 조정하기 위한 텍스트(예: 쿼리-답변, 동일한 의미를 전달하는 텍스트 등)
LLM: LLM의 유사성을 높여 임베딩 품질이 향상됩니다.
의미론적으로 가까운 텍스트의 벡터 표현을 생성했습니다(Hadsell et al., 2006). 전-
풍부한 대조 학습 프레임워크에는 Sentence-BERT(Reimers 및 Gurevych,
2019) 다중 손실 기능과 결합된 듀얼 인코더 네트워크 아키텍처는 다음과 같습니다.
지도 방식으로 텍스트 임베딩을 미세 조정하는 데 사용됩니다. SimCSE(Gao et al., 2021)는 제안합니다.
데이터 쌍을 생성하기 위한 데이터 확대 전략으로 고유한 LLM 드롭아웃 마스크를 사용합니다.
대조 객체에 임베딩 LLM의 감독되지 않은 미세 조정을 위한 유사한 임베딩
tive. Schick 및 Sch¨ utze(2021)는 생성 LLM을 사용하여 유용한 레이블이 있는 텍스트 쌍을 만듭니다.
Embedding-LLM의 감독되지 않은 미세 조정을 위해. 또한 Wang et al. (2023)은 다음과 같은 일반 사항에 의존합니다.
광범위한 합성 교육 데이터를 생성하는 기본 LLM(예: GPT-3.5-turbo 및 GPT-4)
여러 작업과 언어에 걸쳐: 이 데이터는 Mistral-7b를 미세 조정하는 데 활용됩니다.
더 나은 삽입을 생성하기 위한 디코더 전용 LLM. Suet al. (2022) 텍스트 발췌 확장
포함이 사용될 작업을 설명하는 자유 텍스트 지침과 함께 포함됩니다.
위해. 전반적으로, 임베딩 LLM을 대조적으로 미세 조정하는 데 활용되는 일반적인 패러다임
학습은 텍스트 쌍 모음을 활용하는 대조 사전 훈련 단계에 의존합니다.
약한 감독에 의해 반자동으로 생성된 후 미세 조정 단계가 수행됩니다.
LLM은 주석이 달린 고품질 데이터 세트를 사용하여 개선됩니다(Li et al., 2023; Wang
1. GitHub 저장소(https://github.com/iqvianlp/llm-onto-infuse/)에서 구현 가능합니다.
2

대규모 언어 모델을 위한 온톨로지 강화 표현 학습을 향하여
외., 2022). 데이터 증대 접근 방식 외에도 두 가지 추가 핵심 요소가 유용합니다.
더 나은 성과를 내기 위해 활용되는 대조 학습 프레임워크의 효율성을 높이기 위해
텍스트 임베딩은 (i) 훈련을 구성할 텍스트 쌍을 선택하는 전략입니다.
샘플 및 (ii) 훈련 목표(예: 손실 함수) 선택(Wang 및 Dou,
2023). Liu et al. (2020), UMLS 메타에서 검색된 생물의학 개념의 동의어
유의어 사전(Bodenreider, 2004)은 대조를 통해 임베딩 LLM을 미세 조정하는 데 활용됩니다.
학습. 이에 비해 우리의 존재론적 지식 주입 접근법은 다음을 목표로 합니다.
임베딩-LLM은 다음을 수행합니다. (i) 보다 풍부한 언어적 및 구조적 특징을 활용합니다.
온톨로지의 특성(동의어를 넘어) (ii) 전체 문장의 텍스트를 활용합니다(대신
명사구) 임베딩 LLM을 미세 조정합니다. (iii) 새롭고 자동화된 접근 방식 제안
훈련 텍스트 쌍을 생성합니다.
3 Embedding-LLM에 존재론적 지식을 주입하는 작업 흐름
임베딩-LLM에 존재론적 지식을 주입하기 위해 제안된 접근 방식은 린-LLM에 의존합니다.
형태적 특징 - 동의어 및 정의 - 그리고 구조적 특징 - 분류학적
관계 - 온톨로지에 의해 정의된 일련의 개념을 특징짓는 것입니다. 더 자세하게
다음 섹션에서는 대부분의 온톨로지가 공유하는 이러한 기능을 지원하기 위해 활용합니다.
(i) 온톨로지의 개념을 설명하는 텍스트 발췌문의 생성 및
(ii) 이러한 텍스트 발췌문을 유사하거나 유사하지 않은 쌍으로 효과적으로 집계합니다.
Embedding-LLM을 미세 조정하는 데 활용됩니다.
3.1 대조 학습을 통한 임베딩-LLM 미세 조정
다음에 의존하여 수집된 텍스트 정보(즉, 존재론적 개념의 정의)
참조 온톨로지는 그러한 LLM을 미세 조정하여 선택한 임베딩 LLM에 주입됩니다.
모순적인 목표에서.
3.1.1 대조적인 학습 구조와 훈련 목표
실험에서 우리는 Chen et al.이 설명한 대조 학습 프레임워크에 의존합니다.
(2020) 존재론적 지식 주입을 수행합니다. 원칙적으로 우리는 존재론적 요소를 주입할 수 있습니다.
주어진 텍스트 t에 대해 생성할 수 있는 임베딩 LLM(EM B)에 대한 지식
응답 조밀한 벡터 표현 ht = EM B(t) ∈ Rn, 여기서 n은
ht의 차원, 텍스트 삽입 2. 우리가 처리할 수 있는 컬렉션이 있다고 가정해 보겠습니다.
I 의미상 관련된 텍스트 쌍( ti, t+
i ), 여기서 0 < i < = I입니다. N개의 배치를 고려합니다.
의미상 관련된 텍스트 쌍, 해당 임베딩 쌍( hi, h+
나) 그럴 수 있다
LLM(EM B)을 사용하여 계산됩니다. 범주형 교차 엔트로피 손실이 활용됩니다.
각 임베딩에 대해 식별(즉, 연관된 클래스 예측)을 선호합니다.
to) 관련 포지티브 임베딩 h+
i : 동일한 다른 임베딩 쌍의 샘플
배치는 노이즈로 간주됩니다. InfoNCE 손실(Oord)이라고 하는 이 훈련 목표는
2. 고려된 특정 시나리오 및 embedding-LLM에 따라 임베딩 ht가 생성될 수 있습니다.
단일 토큰 임베딩 풀링을 포함하거나 특수 목적을 고려한 별도의 전략을 통해
embedding-LLM의 토큰(예: CLS 토큰)
3

프란체스코 론자노와 제이 나나바티
et al., 2018)은 다음 공식으로 설명됩니다.
lossi = −log esim(hi,h+
나는 )/τ
PN
i=1 esim(안녕하세요,h+
j )/τ (1)
여기서 N은 배치 크기이고 τ는 온도입니다. sim(p, q)는 유사성 함수입니다.
임베딩 p와 q 사이: 코사인 유사성을 사용하는 것이 일반적인 관행입니다.
InfoNCE 손실을 활용하면 학습된 임베딩의 품질이 향상되는 것으로 나타났습니다.
각 배치에서 의미상 관련된 텍스트의 각 쌍( ti, t+
나), 하나
(또는 그 이상) 하드 네거티브 텍스트가 포함됩니다(Chen et al., 2017; Gao et al., 2021). 주어진
한 쌍의 긍정 텍스트, 연관된 하드 부정 샘플 w는 의미론적으로
텍스트 ti 및 t+와 구별됨
i , 임베딩 hw = EM B(w)가 특성화되더라도
긍정적인 텍스트(예: hi 및 h+)의 임베딩과 높은 의미론적 유사성을 통해
나).
따라서 각 긍정 텍스트 쌍에 대해 하나 이상의 하드 부정 텍스트가 선택되면 각
고려된 대조 학습 프레임워크 및 훈련에 의해 활용되는 훈련 샘플
목표는 텍스트 튜플로 표시됩니다( ti, t+
나, WHN 1
나, ..., wHN K
i , ) 여기서 ti 및
t+
나는 한 쌍의 긍정적인 텍스트를 나타내고, wHN k는
0 < i < = K인 i 는 연관된 K입니다.
하드 네거티브 샘플 3.
3.1.2 온톨로지 기반의 훈련 샘플 생성
이 섹션에서는 유용한 훈련 샘플을 만들기 위해 고안한 새로운 절차를 설명합니다.
대조적으로 우리가 선택한 임베딩-LLM에 존재론적 지식을 주입합니다.
목표. 고려된 개념에 포함된 개념의 종합적 정의를 생성한 후
생성적 LLM을 유도하여 온톨로지를 생성하기 위해 이러한 정의를 활용합니다.
훈련 샘플을 통해 긍정적인 텍스트 쌍과 관련 하드 부정적인 텍스트를 선택합니다.
LLM에게 합성 개념 정의를 생성하도록 요청: 우리의 존재론적
지식 주입 접근법은 지식을 설명하는 텍스트 콘텐츠의 가용성에 기반합니다.
선택의 온톨로지에 의해 공식화된 개념: 현재 설정에서 우리는 개념에 중점을 둡니다.
정의4. 온톨로지는 개념의 (일부) 정의를 포함할 수 있습니다. 보장하다
각 개념과 관련된 적어도 하나의 정의의 가용성, 생성적 LLM은 다음과 같습니다.
합성 정의를 생성하라는 메시지가 표시됩니다. 온톨로지 개념의 각 동의어에 대해 하나의
해당 개념의 문장 종합 정의가 수집됩니다(그림 1의 부분 (a) 참조). 는
정의 생성 프롬프트의 구조 i
